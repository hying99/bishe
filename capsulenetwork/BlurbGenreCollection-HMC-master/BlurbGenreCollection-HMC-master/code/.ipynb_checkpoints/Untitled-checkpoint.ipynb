{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'first'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cc24a60becf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdev_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_cats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cats'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcats\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_cats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'first'"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import thinc.extra.datasets\n",
    "\n",
    "def load_data(limit=0, split=0.8):\n",
    "    \"\"\"Load data from the IMDB dataset.\"\"\"\n",
    "    # Partition off part of the train data for evaluation\n",
    "    train_data, _ = thinc.extra.datasets.imdb()\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{'POSITIVE': bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data()\n",
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))\n",
    "print train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from BeautifulSoup import BeautifulStoneSoup\n",
    "import os\n",
    "\n",
    "\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "from spacy.en import English\n",
    "parser = English()\n",
    "\n",
    "def loadData():\n",
    "    directory = '/home/rami/Documents/Bachelorarbeit/crawler/final/'\n",
    "    data = []\n",
    "    #for filename in os.listdir(directory):\n",
    "    categories = []\n",
    "    soup = BeautifulSoup(open(\"/home/rami/Documents/Bachelorarbeit/crawler/final/1.txt\", 'rt').read())\n",
    "    for t in soup.findAll('topics'):\n",
    "        s1 = BeautifulSoup(t)\n",
    "        for t1 in soup.findAll('d0'):\n",
    "            categories.append(t1)\n",
    "        for t1 in soup.findAll('d1'):\n",
    "            categories.append(t1)\n",
    "    data.append(soup(\"body\"), categories)\n",
    "    print (data)\n",
    "    #soup.find_all('BODY')\n",
    "\n",
    "\n",
    "loadData()\n",
    "        \n",
    "    \n",
    "#Custom transformer using spaCy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic utility function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "#Create spacy tokenizer that parses a sentence and generates tokens\n",
    "#these can also be replaced by word vectors \n",
    "def spacy_tokenizer(sentence):\n",
    "    tokens = parser(sentence)\n",
    "    tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
    "    tokens = [tok for tok in tokens if (tok not in stopwords and tok not in punctuations)] \n",
    "    return tokens\n",
    "\n",
    "#create vectorizer object to generate feature vectors, we will use custom spacyâ€™s tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "#classifier = LinearSVC()\n",
    "classifier = MultinomialNB()\n",
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
